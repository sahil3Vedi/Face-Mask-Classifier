{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Mask Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM32++ZC87l1Q+uYlfZtfNU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahil3Vedi/Face-Mask-Classifier/blob/master/Face_Mask_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRWpvUEieGfJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c76dc15b-d923-4658-ccdb-52638c99fdd7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmyERVymvNeR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35889518-4ad1-4e62-d4ee-3b69786e171b"
      },
      "source": [
        "import cv2,os\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "\n",
        "data_path='drive/My Drive/Face Mask Detection'\n",
        "categories=os.listdir(data_path)\n",
        "labels=[i for i in range(len(categories))]\n",
        "\n",
        "label_dict=dict(zip(categories,labels))\n",
        "\n",
        "data=[]\n",
        "target=[]\n",
        "\n",
        "for category in categories:\n",
        "    folder_path=os.path.join(data_path,category)\n",
        "    img_names=os.listdir(folder_path)\n",
        "        \n",
        "    for img_name in img_names:\n",
        "        img_path=os.path.join(folder_path,img_name)\n",
        "        img=cv2.imread(img_path)\n",
        "\n",
        "        try:\n",
        "            gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) \n",
        "            resized=cv2.resize(gray,(100, 100))\n",
        "            data.append(resized)\n",
        "            target.append(label_dict[category])\n",
        "\n",
        "        except Exception as e:\n",
        "            print('Exception:',e)\n",
        "            \n",
        "\n",
        "data=np.array(data)/255.0\n",
        "data=np.reshape(data,(data.shape[0],100, 100,1))\n",
        "target=np.array(target)\n",
        "new_target=np_utils.to_categorical(target)\n",
        "\n",
        "DATA_LOC = 'drive/My Drive/Face Mask Detection/data.npy'\n",
        "TARGET_LOC = 'drive/My Drive/Face Mask Detection/target.npy'\n",
        "\n",
        "np.save(DATA_LOC,data)\n",
        "np.save(TARGET_LOC,new_target)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqulhu5S1Qn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation,Flatten,Dropout\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONcBOovA3tkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Sequential()\n",
        "\n",
        "model.add(Conv2D(100,(3,3),input_shape=data.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(100,(3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(50,activation='relu'))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV_nQKXW4HVp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "5566693c-0406-49fe-9f51-ebe51735cb5d"
      },
      "source": [
        "train_data,test_data,train_target,test_target=train_test_split(data,new_target,test_size=0.1)\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "  'model-{epoch:03d}.model',\n",
        "  monitor='val_loss',\n",
        "  verbose=0,\n",
        "  save_best_only=True,\n",
        "  mode='auto')\n",
        "\n",
        "history=model.fit(\n",
        "  train_data,\n",
        "  train_target,\n",
        "  epochs=20,\n",
        "  callbacks=[checkpoint],\n",
        "  validation_split=0.2)\n",
        "\n",
        "print(model.evaluate(test_data,test_target))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 990 samples, validate on 248 samples\n",
            "Epoch 1/20\n",
            "990/990 [==============================] - 45s 45ms/step - loss: 0.7649 - accuracy: 0.5465 - val_loss: 0.6537 - val_accuracy: 0.5202\n",
            "Epoch 2/20\n",
            "990/990 [==============================] - 49s 49ms/step - loss: 0.6050 - accuracy: 0.6788 - val_loss: 0.5161 - val_accuracy: 0.7097\n",
            "Epoch 3/20\n",
            "990/990 [==============================] - 46s 47ms/step - loss: 0.4474 - accuracy: 0.8030 - val_loss: 0.3709 - val_accuracy: 0.8387\n",
            "Epoch 4/20\n",
            "990/990 [==============================] - 45s 46ms/step - loss: 0.3350 - accuracy: 0.8535 - val_loss: 0.2574 - val_accuracy: 0.9153\n",
            "Epoch 5/20\n",
            "990/990 [==============================] - 49s 49ms/step - loss: 0.2470 - accuracy: 0.9121 - val_loss: 0.2090 - val_accuracy: 0.9073\n",
            "Epoch 6/20\n",
            "990/990 [==============================] - 45s 46ms/step - loss: 0.1733 - accuracy: 0.9384 - val_loss: 0.1735 - val_accuracy: 0.9315\n",
            "Epoch 7/20\n",
            "990/990 [==============================] - 47s 47ms/step - loss: 0.1432 - accuracy: 0.9566 - val_loss: 0.1794 - val_accuracy: 0.9274\n",
            "Epoch 8/20\n",
            "990/990 [==============================] - 46s 46ms/step - loss: 0.1145 - accuracy: 0.9586 - val_loss: 0.1287 - val_accuracy: 0.9556\n",
            "Epoch 9/20\n",
            "990/990 [==============================] - 47s 47ms/step - loss: 0.0958 - accuracy: 0.9677 - val_loss: 0.1403 - val_accuracy: 0.9516\n",
            "Epoch 10/20\n",
            "990/990 [==============================] - 46s 47ms/step - loss: 0.0731 - accuracy: 0.9747 - val_loss: 0.1731 - val_accuracy: 0.9355\n",
            "Epoch 11/20\n",
            "990/990 [==============================] - 46s 46ms/step - loss: 0.0501 - accuracy: 0.9828 - val_loss: 0.1440 - val_accuracy: 0.9637\n",
            "Epoch 12/20\n",
            "990/990 [==============================] - 45s 45ms/step - loss: 0.0378 - accuracy: 0.9879 - val_loss: 0.1586 - val_accuracy: 0.9476\n",
            "Epoch 13/20\n",
            "990/990 [==============================] - 45s 45ms/step - loss: 0.0637 - accuracy: 0.9768 - val_loss: 0.1955 - val_accuracy: 0.9274\n",
            "Epoch 14/20\n",
            "990/990 [==============================] - 44s 45ms/step - loss: 0.0364 - accuracy: 0.9909 - val_loss: 0.1763 - val_accuracy: 0.9476\n",
            "Epoch 15/20\n",
            "990/990 [==============================] - 49s 49ms/step - loss: 0.0203 - accuracy: 0.9949 - val_loss: 0.1720 - val_accuracy: 0.9516\n",
            "Epoch 16/20\n",
            "990/990 [==============================] - 46s 46ms/step - loss: 0.0169 - accuracy: 0.9970 - val_loss: 0.1392 - val_accuracy: 0.9677\n",
            "Epoch 17/20\n",
            "990/990 [==============================] - 45s 46ms/step - loss: 0.0116 - accuracy: 0.9990 - val_loss: 0.1563 - val_accuracy: 0.9637\n",
            "Epoch 18/20\n",
            "990/990 [==============================] - 45s 45ms/step - loss: 0.0078 - accuracy: 0.9990 - val_loss: 0.1576 - val_accuracy: 0.9637\n",
            "Epoch 19/20\n",
            "990/990 [==============================] - 45s 45ms/step - loss: 0.0145 - accuracy: 0.9960 - val_loss: 0.1974 - val_accuracy: 0.9395\n",
            "Epoch 20/20\n",
            "990/990 [==============================] - 45s 45ms/step - loss: 0.1053 - accuracy: 0.9566 - val_loss: 0.1641 - val_accuracy: 0.9355\n",
            "138/138 [==============================] - 2s 12ms/step\n",
            "[0.20739935576051904, 0.9275362491607666]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6zv8ZFiE83i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_LOC = 'drive/My Drive/Face Mask Detection/facemask_classifier.model'\n",
        "model.save(MODEL_LOC)"
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}